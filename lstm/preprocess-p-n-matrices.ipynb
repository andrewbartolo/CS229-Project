{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordsList (400000 words) loaded.\n",
      "wordVectors loaded.\n",
      "180682\n",
      "180682\n",
      "hollywood\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'positiveReviews/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89680d7fc199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordsList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhollywoodIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mpositiveFiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'positiveReviews/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positiveReviews/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positiveReviews/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mnegativeFiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'negativeReviews/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negativeReviews/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negativeReviews/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positiveReviews/'"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# This is a utility program that generates the four index matrices,\n",
    "# pIDsMatrix-train.npy et. al. These files are precomputed, so you can just use\n",
    "# them outright for training and testing.\n",
    "#\n",
    "# NOTE - if for whatever reason you do want to recompute the matrices from\n",
    "# scratch, note that script is set up to process the training set. To process\n",
    "# the test set instead, replace every instance of \"train\" with \"test.\"\n",
    "################################################################################\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from random import randint\n",
    "import datetime\n",
    "from bisect import bisect_left\n",
    "\n",
    "UNKNOWN_WORD_VECTOR_IDX = 399999\n",
    "nPFiles = 12500\n",
    "nNFiles = 12500\n",
    "ckptInterval = 10000\n",
    "\n",
    "###############################################\n",
    "############### HYPERPARAMETERS ###############\n",
    "###############################################\n",
    "numDimensions = 300\n",
    "maxSeqLength = 250 # truncate reviews longer than this\n",
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000 #100K\n",
    "###############################################\n",
    "\n",
    "def binarySearchIndex(a, x):\n",
    "    'Locate the leftmost value exactly equal to x'\n",
    "    i = bisect_left(a, x)\n",
    "    if i != len(a) and a[i] == x:\n",
    "        return i\n",
    "    raise ValueError\n",
    "\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "# not the embeddings matrix, but the list\n",
    "wordsList = np.load('wordsList-lexic-sorted.npy').tolist()\n",
    "wordVectors = np.load('wordVectors-lexic-sorted.npy')\n",
    "\n",
    "nWordsInDict = len(wordsList)\n",
    "print(\"wordsList (%d words) loaded.\" % nWordsInDict)\n",
    "print(\"wordVectors loaded.\")\n",
    "    \n",
    "positiveFiles = ['../stanford_train/pos/' + f for f in listdir('../stanford_train/pos/') if isfile(join('../stanford_train/pos/', f))]\n",
    "negativeFiles = ['../stanford_train/neg/' + f for f in listdir('../stanford_train/neg/') if isfile(join('../stanford_train/neg/', f))]\n",
    "\n",
    "print(len(positiveFiles))\n",
    "print(len(negativeFiles))\n",
    "\n",
    "\n",
    "# TODO truncates at 250, this may be ok though\n",
    "# This will take some time - preprocess and save instead\n",
    "def generateMatrixOfWordIndices(files, indexMatrix):\n",
    "    for fileIdx, f in enumerate(files):\n",
    "        if fileIdx % 1000 == 0:\n",
    "            print(\"Processed %d files\" % fileIdx)\n",
    "        with open(f, 'r', encoding='utf-8') as review:\n",
    "            wordIdx = 0\n",
    "            # each review only has one line, but w/e\n",
    "            for line in review.readlines():\n",
    "                cleanLine = cleanSentences(line)\n",
    "                split = cleanLine.split()\n",
    "                for word in split:\n",
    "                    try:\n",
    "                        #indexMatrix[fileIdx][wordIdx] = binarySearchIndex(wordsList, word)\n",
    "                        indexMatrix[fileIdx][wordIdx] = binarySearchIndex(wordsList, word)\n",
    "                    except ValueError:\n",
    "                        indexMatrix[wordIdx] = UNKNOWN_WORD_VECTOR_IDX\n",
    "                    wordIdx = wordIdx + 1\n",
    "                    if wordIdx == maxSeqLength:\n",
    "                        break\n",
    "\n",
    "# TODO dedup with ^^^^\n",
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize, maxSeqLength],dtype='int32')\n",
    "    cleanSentence = cleanSentences(sentence)\n",
    "    split = cleanSentence.split()\n",
    "    for idxCtr, word in enumerate(split):\n",
    "        try:\n",
    "            #sentenceMatrix[0, idxCtr] = binarySearchIndex(wordsList, word)\n",
    "            sentenceMatrix[0, idxCtr] = binarySearchIndex(wordsList, word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0, idxCtr] = UNKNOWN_WORD_VECTOR_IDX\n",
    "    return sentenceMatrix\n",
    "\n",
    "# Right now, these are ALL TRAINING (see updated bigger dataset)\n",
    "pMatrix = np.zeros((nPFiles, maxSeqLength), dtype='int32')\n",
    "nMatrix = np.zeros((nNFiles, maxSeqLength), dtype='int32')\n",
    "\n",
    "generateMatrixOfWordIndices(positiveFiles, pMatrix)\n",
    "generateMatrixOfWordIndices(negativeFiles, nMatrix)\n",
    "\n",
    "np.save('pIDsMatrix-train.npy', pMatrix)\n",
    "np.save('nIDsMatrix-train.npy', nMatrix)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
