{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word list!\n",
      "Loaded the word list!\n",
      "Loading word vectors!\n",
      "Loaded the word vectors!\n",
      "Going through Positive Files\n",
      "Positive files finished\n",
      "Going through Negative Files\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5713167\n",
      "The average number of words in the files is 228.52668\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1bcdcbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going through Positive Files for indices\n",
      "Positive files finished\n",
      "Going through Negative Files for indices\n",
      "Negative files finished\n",
      "(25000, 250)\n",
      "Making Input Data Matrix\n",
      "Input Data Matrix Loaded\n",
      "Positive files finished\n",
      "(25000, 12500)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "###Import Testing Data###\n",
    "#########################\n",
    "\n",
    "#For detailed comments read \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "pwd='/Users/pulkit/Google Drive/Stan Courses/4. Fall 2017/CS229 ML/Project/CS229-Project/'\n",
    "datapath=pwd+'stanford_test/'\n",
    "\n",
    "print('Loading word list!')\n",
    "wordsList = np.load(datapath+'wordsList-lexic-sorted.npy').tolist()\n",
    "print('Loaded the word list!')\n",
    "\n",
    "print('Loading word vectors!')\n",
    "wordVectors = np.load(datapath+'wordVectors-lexic-sorted.npy')\n",
    "print ('Loaded the word vectors!')\n",
    "\n",
    "#Dimensionality of Word Vector in the word-to-vec dictionary\n",
    "wordEncodingLen=50\n",
    "\n",
    "positiveFiles = [datapath+'pos/' + f for f in listdir(datapath+'pos/') if isfile(join(datapath+'pos/', f))]\n",
    "negativeFiles = [datapath+'neg/' + f for f in listdir(datapath+'neg/') if isfile(join(datapath+'neg/', f))]\n",
    "numWords = []\n",
    "\n",
    "print('Going through Positive Files')\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "print('Going through Negative Files')\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))\n",
    "\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()\n",
    "\n",
    "#define for string cleaning\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "#define for finding index in wordvec\n",
    "def findIndex(search_list, begin, end, key):\n",
    "    mid = int((end - begin + 1)/2) + begin\n",
    "    if end == begin:\n",
    "        if search_list[mid] == key:\n",
    "            return mid\n",
    "        else:\n",
    "            return -1\n",
    "    if end == begin + 1:\n",
    "        if search_list[begin] == key:\n",
    "            return begin\n",
    "        if search_list[end] == key:\n",
    "            return end\n",
    "        else:\n",
    "            return -1\n",
    "    if search_list[mid] < key:\n",
    "        return findIndex(search_list, mid, end, key)\n",
    "    return findIndex(search_list, begin, mid, key)\n",
    "\n",
    "maxSeqLength=250\n",
    "\n",
    "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "print('Going through Positive Files for indices')\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\") as f:\n",
    "        indexCounter = 0\n",
    "        line=f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                ids[fileCounter][indexCounter] = findIndex(wordsList, 0, len(wordsList)-1, word)\n",
    "            except ValueError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unknown words\n",
    "            indexCounter = indexCounter + 1\n",
    "            if indexCounter >= maxSeqLength:\n",
    "                break\n",
    "        fileCounter = fileCounter + 1 \n",
    "print('Positive files finished')\n",
    "\n",
    "print('Going through Negative Files for indices')\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\") as f:\n",
    "        indexCounter = 0\n",
    "        line=f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                ids[fileCounter][indexCounter] = findIndex(wordsList, 0, len(wordsList)-1, word)\n",
    "            except ValueError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unknown words\n",
    "            indexCounter = indexCounter + 1\n",
    "            if indexCounter >= maxSeqLength:\n",
    "                break\n",
    "        fileCounter = fileCounter + 1 \n",
    " #Pass into embedding function and see if it evaluates. \n",
    "print('Negative files finished')\n",
    "\n",
    "print(ids.shape)\n",
    "\n",
    "\n",
    "labels=-1*np.ones(numFiles)\n",
    "labels[0:int(numFiles/2)]=np.ones(int(numFiles/2))\n",
    "\n",
    "#print(np.unique(labels))\n",
    "print('Making Input Data Matrix')\n",
    "\n",
    "#Choose feature type:\n",
    "#'allVectors': as all vectors implying each example is 12500 dimensional\n",
    "#'meanVectors': as all vectors implying each example is 50 dimensional\n",
    "\n",
    "featureType='allVectors'\n",
    "\n",
    "if featureType=='allVectors':\n",
    "    inputData=np.zeros((numFiles,maxSeqLength*wordEncodingLen))\n",
    "    for i in range(numFiles):\n",
    "            for j in range(maxSeqLength):\n",
    "                    inputData[i,j*wordEncodingLen:(j+1)*wordEncodingLen]=wordVectors[ids[i,j],]\n",
    "elif featureType=='meanVectors':\n",
    "    inputData=np.zeros((numFiles,wordEncodingLen))\n",
    "    for i in range(numFiles):\n",
    "        inputData[i,0:wordEncodingLen]=np.mean(wordVectors[ids[i,:],],axis=0)\n",
    "print('Input Data Matrix Loaded')\n",
    "\n",
    "print('Positive files finished')\n",
    "print((inputData.shape))\n",
    "\n",
    "X_test=inputData\n",
    "y_test=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=10000000.0,\n",
      "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=1e-05, verbose=0, warm_start=False)\n",
      "Computing Feature Set\n",
      "Feature Set Computed\n",
      "Predicting\n",
      "(25000,)\n",
      "Misclassified Fraciton on Test Dataset=0.34012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8202, 4298],\n",
       "       [4205, 8295]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Model, kernel and Predict\n",
    "label=\"linear_with_n12500.txt\"\n",
    "kernel='linear'\n",
    "\n",
    "svm_model = joblib.load(label) \n",
    "\n",
    "print(svm_model)\n",
    "# Make appropriate features\n",
    "\n",
    "print('Computing Feature Set')\n",
    "if kernel=='linear':\n",
    "    X_test_newFeatures=X_test\n",
    "elif kernel=='poly2':\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_test_newFeatures=poly.fit_transform(X_test.toarray())\n",
    "elif kernel=='poly3':\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    X_test_newFeatures=poly.fit_transform(X_test.toarray())\n",
    "elif kernel=='RBF':\n",
    "    rbf_feature = RBFSampler(gamma=1, random_state=1)#, n_components=25000)\n",
    "    X_test_newFeatures = rbf_feature.fit_transform(X_test)\n",
    "print('Feature Set Computed')\n",
    "\n",
    "print('Predicting')\n",
    "y_model=svm_model.predict(X_test_newFeatures)\n",
    "print(y_model.shape)\n",
    "\n",
    "#print(np.unique(y_model))\n",
    "\n",
    "misclassifiedFraction=(np.sum(np.fabs(y_model-y_test)))/(2*y_test.size)\n",
    "print('Misclassified Fraciton on Test Dataset='+str(misclassifiedFraction))\n",
    "confusion_matrix(y_test,y_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
